We previously saw that how to do a [[01 - Blind search|blind search]] when we have no way of telling if the actions taken will lead to the goal or not.

Here we will discuss how to exploit a task-specific **measure of goodness** to try to reach the goal more quickly or a more desirable goal state.

We define the **heuristic function** $h'(n)$ as a function that assigns to each node $n$, an estimate of the optimal path from $n$ to a goal node, assuming that $h'$ is **non negative** and that $h'(n)=0\iff \text{is\_goal(n)}$.

>[!Example] Sliding puzzle
>In the [15 puzzle](https://en.wikipedia.org/wiki/15_puzzle) we can use the following heuristics:
>- $h_1'(n)$: number of misplaced tiles
>- $h'_2(n)$: sum of Manhattan distance of each tile

### Best first search
The idea behind this [[Algoritmi greedy|greedy algorithm]] is to always explore the most promising path first, this can be done by choosing the action that follows the node with the minimal value of the expected distance to the goal.

This algorithm has various flaws, it has a _time and space complexity_ of $O(b^d)$, it is **not optimal** since it is greedy, and it is **not complete** since it may not terminate, by going in a loop.
![[Best first search loop.svg]]

### A* search
This algorithm mixes the optimality of [[01 - Blind search#Uniform cost search|uniform cost]] with the heuristic of the best first search.

The **evaluation function** for each node is the following:
$$f(n)=g(n)+h'(n)$$
- $g(n)$: path length from the root to $n$
- $h'(n)$: heuristic prediction of the cost from $n$ to the goal
![[A star search.svg|300]]

#### Optimality of A*
**Lemma**
A heuristic is **consistent** if for every node $n$, every successor $n'$ of $n$ generated by any action $a$ with cost $c(n,a,n')$:
$$h'(n)\leq c(n,a,n')+h'(n')$$
Recalling the [[Triennale/Secondo anno/Algoritmi e strutture dati/Mod. 1/Cammini minimi/Introduzione#Disuguaglianza triangolare|triangular inequality]] we can summarize by saying that the cost of the action summed to the heuristic of the successor should be greater or equal than the value of the heuristic of the current node $n$.

This ensures that $f(n)$ is **non-decreasing** along any path.

**Corollary**
$h'(n)\leq h(n)$, where $h(n)$ is the real (unknown) distance from the goal.

**Theorem**
If $h'$ is _consistent_, then $A^*$ is optimal.
Let $s$ be an optimal goal node, and $x$ a non-optimal goal.
Let $s=n_0,...,n_k$ be the path from the root to $s$, then $\forall i\in{0,...,k}: f(n_i)<f(x)$, in fact:
$$f(n_i)=g(n_i)+h'(n_i)\leq g(n_i)+h(n_i)=g(s)$$
Since _only_ when the node is an optimal goal we have $h'(n)=0$, we can write:
$$f(s)=g(s)+h'(s)=g(s)+0=g(s)$$
so for every path:
$$f(n_i)\leq f(s)=g(s)$$
Considering a non-optimal goal, we know that $g(x)>g(s)$, and thus:
$$g(s)<g(x)=g(x)+h'(x)=f(x)$$
This proves that $A^*$ will never expand a non-optimal goal before it expands the optimal goal node $s$, because $f(s)$ and all its predecessors have smaller $f$ values.

This algorithm is **complete**, with an **exponential complexity** and is optimal.

##### Iterative deepening A*
Similarly to the [[01 - Blind search#Iterative deepening search|IDS]], we can iterate through multiple depth steps in order to reduce the memory consumption.